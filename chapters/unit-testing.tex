\chapter{Unit Testing Framework Choice}
\label{sec:unit-testing-framework-choice}

Section \ref{subsec:unit-testing-fundamentals} introduces basic practices and definitions. Section \ref{sec:unit-boost-google} discusses how the two similar projects, the reference implementation of Lyra2 and of Argon2, address testing. Sections \ref{sec:unit-junit-testng} and \ref{sec:unit-pytest} motivate the choice of tools and techniques for the lyra2-java and the Python build harness projects.

Although the reference implementation of Lyra2 has automated tests, it does not use a dedicated unit testing framework \cite{github:2017:lyra}. This is a justifiable choice which has its advantages. In particular, it allows to keep the complexity of the project lower and not rely on external libraries. The build process is somewhat simplified as well.

Furthermore, when it comes to the \texttt{C/C++} ecosystem, the choice of the framework is not trivial. The authors of Argon2 have also faced this choice and opted out to write their own test harness in \cite{github:2017:argon2-test.c}. Section \ref{sec:unit-boost-google} will provide a plausible explanation. Section \ref{sec:unit-junit-testng} will provide motivation for the choice of the unit testing framework for the lyra2-java port and section \ref{sec:unit-pytest} will describe the test suite for the Python build harness.

\begin{table}
\begin{tabular}{llll}
    Name & License & Parametrization & Parallelism \\ \hline
\texttt{Boost.Test} & Boost Software License & yes & needs 3\textsuperscript{rd} party runner (\texttt{cmake}) \\
\texttt{JUnit4} & Eclipse Public License & yes & needs 3\textsuperscript{rd} party runner (\texttt{mvn}) \\
\texttt{py.test} & MIT & yes & needs 3\textsuperscript{rd} party plugin (\texttt{pytest.xdist})
% Google Test & MIT & parameters? & yes
\end{tabular}
\caption{Important features of several unit testing frameworks.}
\label{table:framework-features-cpp}
\end{table}

\section{\texttt{Boost.Test}}
\label{sec:unit-boost-google}

There is a large choice of unit testing frameworks for the \texttt{C/C++} ecosystem. Given the number of available solutions, their comparison and an educated choice would be a large and daunting task for any developer. This could be one of the reasons why project authors sometimes tend to avoid actually using a unit testing framework. Instead, it is often more practical to write a separate test file that would run a few sanity checks.

Consider the case of Argon2. The in-house \texttt{src/test.c} test program for Argon2 was introduced on 25\textsuperscript{th} of January 2016 \cite{github:2017:argon2}. The commit hash starts with \texttt{7450df88} and it is number 317 out of (current) almost 600 in the version control history. So it is safe to say that this testing was introduced at the later stages of the project when the need for it was apparent \footnote{https://github.com/P-H-C/phc-winner-argon2/issues/85 (visited on 10/23/2017)}.

A similar story could be observed for the reference Lyra2 project \cite{github:2017:lyra}. The rest of this section will explain why a rather popular unit testing library \texttt{Boost.Test} was not used in either of the projects. This particular library was tried because of my personal developer preference. A different developer could attempt the same steps with another library, like \texttt{CTest} or \texttt{Google Test}.

\texttt{Boost} itself is a large collection of different libraries for \texttt{C++}. It was originally founded by Beman Dawes and David Abrahams but today the number of contributors is in the hundreds. The scope of the libraries spans from concurrent programming to regular expressions to linear algebra. There is a formal submission process \footnote{http://www.boost.org/development/submissions.html (visited on 10/23/2017)} for any library that would like to be included into the collection as well as rigorous review in the mailing lists \footnote{http://www.boost.org/community/groups.html\#main (visited on 10/23/2017)}. Many of the ideas that originate in \texttt{Boost} are later adopted by the \texttt{C++} language standard.

The \texttt{Boost.Test} is a unit testing framework which is part of \texttt{Boost}. It is licensed under the Boost Software License which is a free software license, OSI-approved and compatible with GPL. The library documentation is located in \cite{boost:2017:test-docs}.

The main features of the library are summarized in table \ref{table:framework-features-cpp}. When it comes to password hashing, support for test parametrization becomes important because of the common test scenario described in section \ref{subsec:unit-testing-fundamentals}. \texttt{Boost.Test} provides all the common features a unit testing library is expected to have. The tests can be completely decoupled from the implementation, subdivided  into test suits and automatically registered with the test runner. The registration can be accomplished with a single \mintinline{cpp}{#include<...>} and a call to the \mintinline{cpp}{BOOST_AUTO_TEST_CASE} macro, as shown in figure \ref{figure:boost-auto-test-case}.

\begin{figure}
\centering
\begin{minted}{cpp}
#define BOOST_TEST_MODULE example_module_name
#include <boost/test/included/unit_test.hpp>

BOOST_AUTO_TEST_CASE(name_of_test_function) {
    BOOST_TEST(true);
}
  \end{minted}
  \caption{Automatic unit test registration with the \texttt{Boost.Test} framework}
  \label{figure:boost-auto-test-case}
  \end{figure}

Apart from that \texttt{Boost.Test} has a few convenience features. First of all, it was designed to be used as a header-only library. This means that the build process of a project needs only slight modification. Secondly, \texttt{Boost.Test} supports parametrized tests which are called "Data-Driven Test Cases" and can be found in \cite{boost:2017:test-data-driven}. First step is to declare such tests with the special \mintinline{cpp}{BOOST_DATA_TEST_CASE} macro. More details about its usage can be found in \cite{boost:2017:test-docs-data-macro}. The data also has to be wrapped into a dataset. The exact procedure is described in detail in \cite{boost:2017:test-docs-dataset}.

This section should have given the reader a hint that setting up \texttt{Boost.Test} for the real-world usage is not entirely painless. Even though the documentation provides an accurate description of the process, it still takes significant time to set everything up. Therefore it is understandable why Lyra2 and Argon2 projects chose to use their own testing solutions and not take advantage of test parametrization.

\section{\texttt{JUnit} and \texttt{TestNG}}
\label{sec:unit-junit-testng}

\begin{figure}
\small
\begin{minted}[linenos]{java}
@RunWith(Parameterized.class)
public class Lyra2Test {
    @Parameterized.Parameters
    public static Collection<Object[]> setupClass() {
        // Simplified initialization of a YAML data loader
        Yaml yaml = new Yaml();

        // A list of YAML file names with test vectors and resulting hashes
        String[] fnames = new String[] {"test-data-file_0.yml"};
        List<Object[]> entries = new ArrayList<>();

        for (String fname: fnames) {
            // Simplified loading of the YAML data from the file
            for (Object data : yaml.loadAll(reader)) {
                entries.add(new Object[]{data});
            }
        }

        return entries; // data provider has finished, returning result
    }

    private DataEntry entry;

    // Injection of test parameters
    public Lyra2Test(DataEntry entry) {
        this.entry = entry;
    }

    @Test
    public void simpleTest() {

        LyraParams params = new LyraParams(/* use entry to initialize */);

        byte[] hash = new byte[entry.klen];
        byte[] pass = entry.pass.getBytes();
        byte[] salt = entry.salt.getBytes();

        // Run the computation
        Lyra2.phs(hash, pass, salt, params);
        // Fetch the correct hash value
        byte[] correct_hash = pack.bytes(entry.hash);
        // Compare the computation result to the correct hash
        assertArrayEquals(correct_hash, hash);
    }
}
\end{minted}
\normalsize
\caption{A simplified example of lyra2-java parametrized testing with \texttt{JUnit4}.}
\label{fig:junit4-parametrization}
\end{figure}

The Java ecosystem offers \texttt{JUnit}, which is a unit testing framework inspired by \texttt{xUnit}. The latter is a collective name for a specific architecture introduced by \texttt{NUnit}. This architecture is described below.

The main element of \texttt{JUnit} is a \emph{test case} which is usually a class that contains testing logic. Such a class might have special methods called \emph{fixtures} which are responsible for setting up and tearing down the context in which a test is executed. For example, this might include repeatedly creating a set of objects or opening a database connection. The methods marked with the \mintinline{java}{@Before} (respectively, \mintinline{java}{@After}) annotation are executed before (respectively, after) each individual test. The \mintinline{java}{@BeforeClass} (respectively, \mintinline{java}{@AfterClass}) annotation ensures that a method is run exactly once before (respectively, after) the test class is instantiated.

Several test cases can be collected into a single \emph{test suite}. Finally, a program called a \emph{test runner} is responsible for discovering the test cases, running them and reporting the results back to the user. The test runner can be instructed to run (or skip) specific test suits.

As well as \texttt{JUnit}, the Java ecosystem has a unit testing framework called \texttt{TestNG} \cite{testng:2017:home}. Below is a short comparison of the functionality relevant to testing password hashing algorithms.

Firstly, both frameworks allow to implement parametrization tests but the implementation details are different.  \texttt{JUnit4} requires the developer to mark the class with the \mintinline{java}{@RunWith} decorator as well as provide a class method marked with \mintinline{java}{@Parameters} and return a single \mintinline{java}{Collections<Object[]>} of data. On the other hand, \texttt{TestNG} has two distinct mechanisms, one of which uses \texttt{testng.xml} and the other is a \mintinline{java}{@DataProvider} method which returns either a single \mintinline{java}{Object[][]} or an \mintinline{java}{Iterator<Object[]>}. With the first mechanism, the test data is stored separately in \texttt{testng.xml} while the second approach allows to have a function that generates the data \footnote{http://testng.org/doc/documentation-main.html\#parameters (visited on 10/23/2017)}.

Formally, \texttt{TestNG} implements parametrized tests in a more flexible manner. However, in practice the \texttt{testng.xml} is not that widely used and the \mintinline{java}{Collections<Object[]>} \texttt{JUnit4} API is arguably cleaner than the generic-free way of \texttt{TestNG}. Finally, \texttt{JUnit4} is usually readily provided by Java Integrated Development Environments (IDEs) and does not require additional setup. The feature parity with \texttt{TestNG} and general availability were the deciding factors in using this testing framework for lyra2-java.

Figure \ref{fig:junit4-parametrization} provides a simplified example of the way unit tests are organized in lyra2-java. The testing logic is in the \mintinline{java}{simpleTest} method: configuration parameters are constructed using the values from the \mintinline{java}{entry} instance variable, then a call to \mintinline{java}{Lyra2.phs} is made and the resulting hash is compared to the correct answer by the \mintinline{java}{assertArrayEquals} call.

The \mintinline{java}{setupClass} method is marked with the \mintinline{java}{@Parametrized.Parameters} annotation which makes this method the provider of data. The precomputed data comes from several \texttt{YAML} data files whose names are stored in the \mintinline{java}{fnames} variable. More information about the file structure and \texttt{YAML} in general is in section \ref{sec:configuration-and-test-file-format}. The \mintinline{java}{for} loop on line \(12\) sequentially opens the \texttt{YAML} data files, loads their contents and collects them in the \mintinline{java}{entries} variable. Once the \mintinline{java}{setupClass} method returns that variable, it is used by \texttt{JUnit} to initialize several instances of the class, providing each constructor with one element from the \mintinline{java}{entries} array.

This is the application of the parametrized tests approach which allows to run several hundreds of tests for different configurations and input values while writing the test code only once.

\section{Unit Testing with \texttt{py.test}}
\label{sec:unit-pytest}

Python is a very popular high-level general purpose scripting language created by Guido van Rossum. It has a built-in unit testing framework called \texttt{unittest} which comes together with the interpreter. It keeps a fairly compatible interface with the \texttt{xUnit} architecture described in section \ref{sec:unit-junit-testng}. Other two notable unit testing frameworks in Python are \texttt{Nose} and \texttt{py.test}. They both support an \texttt{xUnit} compatible layer and come as an external dependency. The features offered by these two external frameworks are superior to those provided by the built-in \texttt{unittest}.

Parametrized testing is tricky when it comes to a scripting language like Python. Even the built-in \texttt{unittest} framework could dynamically generate test classes, as demonstrated on \mbox{Stackoverflow \footnote{https://stackoverflow.com/a/20870875/1269892 (visited on 10/23/2017)}}. However, there is no \emph{designed} way to do so. The \texttt{Nose} library allows for parametrized testing through an elegant mechanism of Python generators (the \mintinline{python}{yield} keyword) that return functions to be run as test cases. The \texttt{py.test} framework goes the more \texttt{xUnit}-inspired route of using the \mintinline{python}{@mark.parametrized} decorator, see figure \ref{fig:pytest-parametrization}.

Unfortunately, the \texttt{Nose} unit testing framework is currently in maintenance mode. This framework is no longer in active development and therefore is not recommended for new projects. This is why the Python build harness for the reference Lyra2 implementation uses \texttt{py.test}.

\begin{figure}
\begin{minted}[linenos]{python}
import pytest
import subprocess

from pathlib import Path

bindir = Path(__file__).parent.parent.joinpath('bin42')
@pytest.mark.parametrize('path', list(bindir.glob("lyra2-*")))
@pytest.mark.parametrize('pwd', ['password', 'qwerty'])
@pytest.mark.parametrize('salt', ['salt', 'pepper'])
@pytest.mark.parametrize('k', [1, 2])
@pytest.mark.parametrize('t', [1, 2])
@pytest.mark.parametrize('m', [3, 4, 5, 6, 7, 8, 9, 10])
def test_sanity_0(path, pwd, salt, k, t, m):

    result = subprocess.run([path, pwd, salt, str(k), str(t), str(m)])

    assert result.returncode == 0
\end{minted}
\caption{A simplified example of Lyra2 parametrized testing with \texttt{py.test}.}
\label{fig:pytest-parametrization}
\end{figure}

Figure \ref{fig:pytest-parametrization} shows why parametrization testing is important when building different configurations of the reference Lyra2 implementation. Before running those configurations with a long list of parameters it is worth to make sure that the compiled executables actually work. However, writing a test for each individual possible configuration is not feasible. Instead, the first decorator \mintinline{python}{@pytest.mark.parametrize('path')} fetches all filenames that start with \texttt{lyra2-} (convention for Lyra2 executable names) from a specific directory. These names are later passed into a specific unit test by the \texttt{path} parameter.

This parametrized testing approach allows to write the testing logic once and reuse it for any possible Lyra2 configuration produced by the \texttt{Makefile} of the reference project.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Configuration and Test File Format}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:configuration-and-test-file-format}

The data for parametrized tests is stored in YAML files. Those files are produced by the reference Lyra2 project through the Python build harness. Then they are consumed by the \texttt{JUnit4} testing framework of the lyra2-java project. This mechanism allows to make sure that both projects compute the same hash values.

YAML stands for \emph{YAML Ain't Markup Language} and is a superset of JSON, another popular data format. YAML targets human readability and provides native support for custom datatypes: scalars, arrays, structures, etc. Most programming languages provide support for reading and writing of YAML files, including both Java and Python.

A single file in YAML can hold several documents. This is leveraged by the Python build harness: each file corresponds to a single Lyra2 executable. This guarantees that the compile time parameters are fixed. These parameters are stored together with all the runtime parameters and the resulting hash. See figure \ref{fig:yaml-data} for reference. The \texttt{hash} field is stored as an array of strings which ensures that different YAML libraries deduce the content type of this array correctly. The \mintinline{shell}{---} is a delimiter between the two YAML documents. This feature allows to store several sets of data in one file.

The YAML format is also used to store default configuration for the Python build harness of the reference Lyra2 project. It can be found on the \texttt{harness} branch of the forked reference repository in the \mintinline{shell}{harness.yml} file \cite{github:2017:lyra-copy}. The primary parameters are \mintinline{shell}{build_path} and \mintinline{shell}{makefile_path}. The first one defines the location for the compiled Lyra2 executables and the second one points to the original \mintinline{shell}{Makefile}.

The \mintinline{shell}{matrix} group of parameters defines the build matrix. The \mintinline{shell}{option} parameter configures the type of Lyra2 executable built by the \mintinline{shell}{Makefile}, which is a generic version for the \mintinline{shell}{x86_64} architecture by default. The \mintinline{shell}{threads} parameter determines the parallelism degree and is set to 1. The \mintinline{shell}{columns}, \mintinline{shell}{sponge}, \mintinline{shell}{rounds} and \mintinline{shell}{blocks} correspond directly to compile time Lyra2 parameters. Finally, the \mintinline{shell}{bench} parameter determines if the test vectors should be included into the compiled executable. By default it is set to 0 which means those vectors are skipped.

The \mintinline{shell}{data} group of parameters specifies the test vectors which will be used when generating hash values with \mintinline{shell}{./harness.py compute}. That group includes \mintinline{shell}{pass}~---~an array of passwords, \mintinline{shell}{salt}~---~an array of salts, \mintinline{shell}{klen}~---~an array of output lengths (i.e. the length of the hash), \mintinline{shell}{tcost}~---~an array of time costs and finally \mintinline{shell}{mcost}~---~an array of memory costs. The \mintinline{shell}{./harness.py} script generates a Cartesian product of all of the array members and then runs every compiled executable using those values as test vectors. The results are stored in the \mintinline{shell}{data_path} directory which can be configured as well. The \mintinline{shell}{./harness.py} script does not overwrite old hash values, so you will have to remove them manually if regeneration is required.

Finally, compilation flags are also part of the configuration and their defaults can be seen in figure \ref{fig:compile-flags}.

\begin{figure}
    \begin{minted}{yaml}
    blocks: 8
    columns: 16
    hash: [0f, ee, bd, 1f, '00', 2a, 5b, '87', '71', ee]
    klen: 10
    mcost: 3
    pass: password
    rounds: 1
    salt: s
    sponge: blake2b
    tcost: 1
    threads: 1
    ---
    blocks: 8
    columns: 16
    hash: [0f, 7d, e3, 3c, e3, 9e, 0c, f9, 8e, '70']
    klen: 10
    mcost: 10
    pass: password
    rounds: 1
    salt: s
    sponge: blake2b
    tcost: 1
    threads: 1
    \end{minted}
    \caption{An example of a YAML test data file. Two distinct documents are separated with \mintinline{shell}{---}. The real test harness uses \emph{a lot} more YAML documents per one actual file.}
    \label{fig:yaml-data}
  \end{figure}


\begin{figure}
    \begin{minted}{yaml}
    CFLAGS:
      - -std=c99
      - -Wall
      - -pedantic
      - -O3
      - -msse2
      - -ftree-vectorizer-verbose=1
      - -fopenmp
      - -funroll-loops
      - -march=native
      - -Ofast
      - -mprefer-avx128
      - -flto
      \end{minted}
      \caption{The compilation flags used by the reference Lyra2 implementation.}
      \label{fig:compile-flags}
  \end{figure}
